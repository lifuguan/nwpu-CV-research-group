
@article{YANG2022108295,
	abstract = {Recovering 3D voxelized shapes with fine details from single-view 2D images is an extremely challenging and ill-conditioned problem. Most of the existing methods learn the 3D reconstruction process by encoding the 3D shapes and the 2D images into the same low-dimensional latent vector, which lacks the capacity to capture detailed features in the surface of the 3D object shapes. To address this issue, we propose to explore rich intermediate representation for 3D shape reconstruction by using a newly designed network architecture. We first use a two-steam network to infer the depth map and the topology-specific mean shape from the given 2D image, which forms the intermediate representation prediction branch. The intermediate representations capture the global spatial structure and the visible surface geometric structure, which are important for reconstructing high-quality 3D shapes. Based on the obtained intermediate representation, a novel shape transformation network is then proposed to reconstruct the fine details of the whole 3D object shapes. The experimental results on the challenging ShapeNet and Pix3D datasets show that our approach outperforms the existing state-of-the-art methods.},
	author = {Yang Yang and Junwei Han and Dingwen Zhang and Qi Tian},
	doi = {https://doi.org/10.1016/j.patcog.2021.108295},
	issn = {0031-3203},
	journal = {Pattern Recognition},
	keywords = {3D Reconstruction, Shape transformation, Intermediate representations},
	pages = {108295},
	title = {Exploring rich intermediate representations for reconstructing 3D shapes from 2D images},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320321004751},
	volume = {122},
	year = {2022},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0031320321004751},
	bdsk-url-2 = {https://doi.org/10.1016/j.patcog.2021.108295}}
